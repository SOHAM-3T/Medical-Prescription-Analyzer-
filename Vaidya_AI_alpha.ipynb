{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.13",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [
        {
          "sourceId": 12916977,
          "sourceType": "datasetVersion",
          "datasetId": 8173329
        }
      ],
      "dockerImageVersionId": 31090,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": false
    },
    "colab": {
      "name": "Vaidya AI alpha",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SOHAM-3T/Medical-Prescription-Analyzer-/blob/main/Vaidya_AI_alpha.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "source": [
        "# IMPORTANT: SOME KAGGLE DATA SOURCES ARE PRIVATE\n",
        "# RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES.\n",
        "import kagglehub\n",
        "kagglehub.login()\n"
      ],
      "metadata": {
        "id": "imIlAnEz2Mt0"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "source": [
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "\n",
        "soham3ripathy_prescription_data_set_path = kagglehub.dataset_download('soham3ripathy/prescription-data-set')\n",
        "\n",
        "print('Data source import complete.')\n"
      ],
      "metadata": {
        "id": "K9YX7w442Mt3"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Install Required Libraries\n",
        "\n",
        "print(\"Installing Hugging Face Transformers and other required libraries...\")\n",
        "# We need sentencepiece for the tokenizer and difflib for evaluation\n",
        "!pip install -q transformers torch sentencepiece pillow\n",
        "\n",
        "import torch\n",
        "from transformers import DonutProcessor, VisionEncoderDecoderModel, pipeline\n",
        "from PIL import Image\n",
        "import os\n",
        "import json\n",
        "from difflib import SequenceMatcher # To compare the OCR output with ground truth\n",
        "import numpy as np # Import numpy to handle special data types\n",
        "import re\n",
        "\n",
        "print(\"Installation and imports complete.\")"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-08-30T12:06:31.586144Z",
          "iopub.execute_input": "2025-08-30T12:06:31.586792Z",
          "iopub.status.idle": "2025-08-30T12:06:34.783172Z",
          "shell.execute_reply.started": "2025-08-30T12:06:31.586768Z",
          "shell.execute_reply": "2025-08-30T12:06:34.782247Z"
        },
        "id": "gR4nkGZs2Mt4"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 2: Define the Local OCR (Reader) Function\n",
        "\n",
        "try:\n",
        "    print(\"Loading Local OCR Model (Naver-Clova Donut)...\")\n",
        "    ocr_processor = DonutProcessor.from_pretrained('naver-clova-ix/donut-base-finetuned-cord-v2')\n",
        "    ocr_model = VisionEncoderDecoderModel.from_pretrained('naver-clova-ix/donut-base-finetuned-cord-v2')\n",
        "    print(\"OCR Model loaded successfully.\")\n",
        "except Exception as e:\n",
        "    print(f\"Error loading OCR model: {e}\")\n",
        "    ocr_model = None\n",
        "\n",
        "def run_local_ocr(image_path):\n",
        "    \"\"\"\n",
        "    Takes an image path, runs it through a local Donut model, and returns the transcribed text.\n",
        "    \"\"\"\n",
        "    if not ocr_model:\n",
        "        return \"OCR Model not loaded. Cannot process image.\"\n",
        "\n",
        "    try:\n",
        "        image = Image.open(image_path).convert(\"RGB\")\n",
        "\n",
        "        # Prepare image for model\n",
        "        pixel_values = ocr_processor(image, return_tensors=\"pt\").pixel_values\n",
        "\n",
        "        # Prepare decoder inputs\n",
        "        task_prompt = \"<s_cord-v2>\"\n",
        "        decoder_input_ids = ocr_processor.tokenizer(task_prompt, add_special_tokens=False, return_tensors=\"pt\").input_ids\n",
        "\n",
        "        # Move model and inputs to GPU if available\n",
        "        device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "        ocr_model.to(device)\n",
        "        pixel_values = pixel_values.to(device)\n",
        "        decoder_input_ids = decoder_input_ids.to(device)\n",
        "\n",
        "        # Generate output\n",
        "        outputs = ocr_model.generate(\n",
        "            pixel_values,\n",
        "            decoder_input_ids=decoder_input_ids,\n",
        "            max_length=ocr_model.decoder.config.max_position_embeddings,\n",
        "            pad_token_id=ocr_processor.tokenizer.pad_token_id,\n",
        "            eos_token_id=ocr_processor.tokenizer.eos_token_id,\n",
        "            use_cache=True,\n",
        "            num_beams=1,\n",
        "            bad_words_ids=[[ocr_processor.tokenizer.unk_token_id]],\n",
        "            return_dict_in_generate=True,\n",
        "        )\n",
        "\n",
        "        # Decode the output sequence\n",
        "        sequence = ocr_processor.batch_decode(outputs.sequences)[0]\n",
        "\n",
        "        # --- NEW: More Robust Cleanup Logic ---\n",
        "        # This regex finds all text content between the XML-like tags.\n",
        "        # It handles the messy, structured output from the Donut model.\n",
        "        text_snippets = re.findall(r'>([^<]+)<', sequence)\n",
        "\n",
        "        # Join the snippets together to form the clean text\n",
        "        clean_text = \" \".join([snippet.strip() for snippet in text_snippets])\n",
        "\n",
        "        return clean_text\n",
        "\n",
        "    except Exception as e:\n",
        "        return f\"Error during OCR processing: {e}\"\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-08-30T12:14:39.618319Z",
          "iopub.execute_input": "2025-08-30T12:14:39.618942Z",
          "iopub.status.idle": "2025-08-30T12:14:42.61782Z",
          "shell.execute_reply.started": "2025-08-30T12:14:39.618919Z",
          "shell.execute_reply": "2025-08-30T12:14:42.617076Z"
        },
        "id": "psvwB1H92Mt5"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 3: Define the Local NER (Analyst) Function\n",
        "\n",
        "try:\n",
        "    print(\"Loading Local NER Model (Biomedical NER)...\")\n",
        "    ner_pipeline = pipeline(\"token-classification\", model=\"d4data/biomedical-ner-all\", aggregation_strategy=\"simple\")\n",
        "    print(\"NER Model loaded successfully.\")\n",
        "except Exception as e:\n",
        "    print(f\"Error loading NER model: {e}\")\n",
        "    ner_pipeline = None\n",
        "\n",
        "def run_local_ner(text):\n",
        "    \"\"\"\n",
        "    Takes transcribed text, runs it through a local Biomedical NER model,\n",
        "    and returns a structured list of entities.\n",
        "    \"\"\"\n",
        "    if not ner_pipeline:\n",
        "        return {\"error\": \"NER Model not loaded.\"}\n",
        "\n",
        "    try:\n",
        "        ner_results = ner_pipeline(text)\n",
        "        return ner_results\n",
        "    except Exception as e:\n",
        "        return {\"error\": f\"Error during NER processing: {e}\"}\n",
        "\n",
        "# --- FIX: Creating a robust JSON serializer to prevent crashes ---\n",
        "class NpEncoder(json.JSONEncoder):\n",
        "    def default(self, obj):\n",
        "        if isinstance(obj, np.integer):\n",
        "            return int(obj)\n",
        "        if isinstance(obj, np.floating):\n",
        "            return float(obj)\n",
        "        if isinstance(obj, np.ndarray):\n",
        "            return obj.tolist()\n",
        "        return super(NpEncoder, self).default(obj)\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-08-30T12:17:05.144094Z",
          "iopub.execute_input": "2025-08-30T12:17:05.144661Z",
          "iopub.status.idle": "2025-08-30T12:17:05.474147Z",
          "shell.execute_reply.started": "2025-08-30T12:17:05.144638Z",
          "shell.execute_reply": "2025-08-30T12:17:05.473409Z"
        },
        "id": "4CrlZ1k82Mt5"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 4: Run the Full Pipeline & Evaluate\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # --- 1. SET YOUR IMAGE PATH ---\n",
        "    TEST_IMAGE_PATH = \"/kaggle/input/prescription-data-set/Prescription.jpg\"\n",
        "\n",
        "    # --- 2. PASTE YOUR GROUND TRUTH TEXT HERE ---\n",
        "    GROUND_TRUTH_TEXT = \"T. Doxycycline 100mg BD (6) T. Dolo 650mg BD (6) T. Rantac OD (3) T. Cetirizine OD (5) T. Vit C (5)\"\n",
        "\n",
        "    if not os.path.exists(TEST_IMAGE_PATH):\n",
        "        print(f\"\\nERROR: Test image not found at '{TEST_IMAGE_PATH}'\")\n",
        "        print(\"Please upload your prescription image and update the path in the script.\")\n",
        "    else:\n",
        "        print(\"\\n\" + \"=\"*50)\n",
        "        print(\"         STARTING LOCAL TRANSFORMER PIPELINE\")\n",
        "        print(\"=\"*50)\n",
        "\n",
        "        # Stage 1: Run the Local Reader (OCR)\n",
        "        print(f\"\\n[Stage 1] Reading text from image: {os.path.basename(TEST_IMAGE_PATH)}\")\n",
        "        transcribed_text = run_local_ocr(TEST_IMAGE_PATH)\n",
        "        print(f\"--> Model's Transcription: {transcribed_text}\")\n",
        "\n",
        "        # Stage 2: Run the Local Analyst (NER)\n",
        "        print(\"\\n[Stage 2] Analyzing text to find medical entities...\")\n",
        "        structured_data = run_local_ner(transcribed_text)\n",
        "\n",
        "        print(\"\\n\" + \"=\"*50)\n",
        "        print(\"         PIPELINE COMPLETE - STRUCTURED DATA\")\n",
        "        print(\"=\"*50)\n",
        "        # We now use our custom encoder (cls=NpEncoder) to print safely\n",
        "        print(json.dumps(structured_data, indent=2, cls=NpEncoder))\n",
        "\n",
        "        # --- Stage 3: Evaluation ---\n",
        "        print(\"\\n\" + \"=\"*50)\n",
        "        print(\"         EVALUATION vs. GROUND TRUTH\")\n",
        "        print(\"=\"*50)\n",
        "\n",
        "        print(\"\\n--- OCR Performance ---\")\n",
        "        print(f\"Model Output: {transcribed_text}\")\n",
        "        print(f\"Ground Truth: {GROUND_TRUTH_TEXT}\")\n",
        "\n",
        "        similarity = SequenceMatcher(None, transcribed_text.lower(), GROUND_TRUTH_TEXT.lower()).ratio()\n",
        "        print(f\"\\n--> Text Similarity Score: {similarity:.2%}\")\n",
        "\n",
        "        print(\"\\n--- NER Performance ---\")\n",
        "        print(\"Below are the entities the model found. Compare them to what you expected from the ground truth.\")\n",
        "        print(json.dumps(structured_data, indent=2, cls=NpEncoder))\n",
        "\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-08-30T12:17:10.118899Z",
          "iopub.execute_input": "2025-08-30T12:17:10.119462Z",
          "iopub.status.idle": "2025-08-30T12:17:11.562935Z",
          "shell.execute_reply.started": "2025-08-30T12:17:10.119438Z",
          "shell.execute_reply": "2025-08-30T12:17:11.562154Z"
        },
        "id": "8EjIHy6y2Mt6"
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}