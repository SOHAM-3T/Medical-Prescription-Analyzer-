# ğŸ©º Medical Prescription Analyzer

An end-to-end **OCR pipeline for medical prescriptions**, powered by a **fine-tuned Donut (Document Understanding Transformer)** model.  
This project extracts text from handwritten/typed prescriptions and makes it available for further analysis (e.g., medicine recognition, dosage extraction).

---

## ğŸš€ Features
- ğŸ“„ **OCR with Donut** â€” Fine-tuned Donut model on prescription dataset.  
- ğŸ§© **Pipeline Integration** â€” Easily plug into existing medical text-processing workflows.  
- ğŸ“Š **Evaluation** â€” Tracks WER (Word Error Rate) and training loss.  
- ğŸ”§ **Customizable** â€” Extendable to structured parsing (medicine, dosage, duration).  
- ğŸ’¾ **Reusable Model** â€” Saved and reloadable with Hugging Face Transformers.  

---

## ğŸ“‚ Project Structure
Medical-Prescription-Analyzer-/
â”œâ”€â”€ model_fine_tuning/          # Kaggle notebook for fine-tuning Donut
â”‚   â””â”€â”€ fine_tuning_model_gamma.ipynb
â”œâ”€â”€ pipeline/                   # Pipeline notebook for inference & analysis
â”‚   â””â”€â”€ prescription_pipeline.ipynb
â”œâ”€â”€ README.md                   # Project overview
â”œâ”€â”€ requirements.txt            # Dependencies
â”œâ”€â”€ LICENSE                     # MIT License
â””â”€â”€ .gitignore                  # Ignored files

âš™ï¸ Installation

Clone the repo:

git clone https://github.com/SOHAM-3T/Medical-Prescription-Analyzer-.git
cd Medical-Prescription-Analyzer-


Install dependencies:

pip install -r requirements.txt

ğŸ‹ï¸ Fine-Tuning (Optional)

To fine-tune Donut on your own dataset:

from transformers import DonutProcessor, VisionEncoderDecoderModel

# Load pre-trained Donut
processor = DonutProcessor.from_pretrained("naver-clova-ix/donut-base")
model = VisionEncoderDecoderModel.from_pretrained("naver-clova-ix/donut-base")

# Fine-tuning is implemented in model_fine_tuning/fine_tuning_model_gamma.ipynb

ğŸ” Inference Pipeline

Example usage in your pipeline:

from transformers import DonutProcessor, VisionEncoderDecoderModel
from PIL import Image
import torch

MODEL_DIR = "path/to/donut-finetuned-prescription-ocr"

# Load fine-tuned model
processor = DonutProcessor.from_pretrained(MODEL_DIR)
model = VisionEncoderDecoderModel.from_pretrained(MODEL_DIR).to("cuda" if torch.cuda.is_available() else "cpu")

# OCR function
def ocr_prescription(img_path: str):
    image = Image.open(img_path).convert("RGB")
    pixel_values = processor(image, return_tensors="pt").pixel_values.to(model.device)
    outputs = model.generate(pixel_values, max_length=512)
    return processor.batch_decode(outputs, skip_special_tokens=True)[0]

print(ocr_prescription("sample_prescription.jpg"))

ğŸ“Š Results
Metric	Value (10 Epochs)
Training Loss	~4.4
Validation Loss	~4.4
WER	~0.87 â†’ 1.15 (small dataset, unstable)

With a larger dataset and more training epochs, performance will improve significantly.

ğŸ“¦ Model Access

The fine-tuned model is available in:

Kaggle notebook outputs: soham3ripathy/fine-tuning-model-gamma

Can be uploaded as a Kaggle dataset or GitHub release.

ğŸ”® Future Work

Expand dataset for better generalization.

Add structured JSON parsing (medicine, dosage, duration).

Deploy as an API (Flask/FastAPI).

ğŸ¤ Contributing

Pull requests are welcome. For major changes, please open an issue first to discuss what youâ€™d like to improve.

ğŸ“œ License

MIT License
